
    def _is_ollama_available(self) -> bool:
        """Check if Ollama is available and running."""
        try:
            import ollama
            # Try to connect to Ollama
            logger.info("Attempting to connect to Ollama...")
            response = ollama.list()
            logger.info("Ollama connection successful")
            return True
        except Exception as e:
            logger.warning(f"Ollama connection failed: {str(e)}")
            return False
    
    def _is_anthropic_available(self) -> bool:
        """Check if Anthropic API key is available."""
        import os
        return bool(os.getenv('ANTHROPIC_API_KEY'))
    
    def _generate_with_ollama(self, state: AnalysisState) -> str:
        """Generate report using Ollama LLM."""
        try:
            import ollama
            import json
            
            # Prepare context data for the LLM
            context_data = self._prepare_context_data(state)
            
            # Create a comprehensive prompt
            prompt = self._create_llm_prompt(context_data)
            
            # Call Ollama with Qwen model (or default if Qwen not available)
            try:
                response = ollama.chat(
                    model='qwen2.5:14b',  # Try Qwen first
                    messages=[
                        {
                            'role': 'system',
                            'content': 'You are an expert HR analyst and career coach. Generate detailed, personalized CV skill gap analysis reports with actionable insights.'
                        },
                        {
                            'role': 'user',
                            'content': prompt
                        }
                    ]
                )
                return response['message']['content']
            except Exception:
                # Fallback to llama3 if qwen not available
                response = ollama.chat(
                    model='llama3',
                    messages=[
                        {
                            'role': 'system',
                            'content': 'You are an expert HR analyst and career coach. Generate detailed, personalized CV skill gap analysis reports with actionable insights.'
                        },
                        {
                            'role': 'user',
                            'content': prompt
                        }
                    ]
                )
                return response['message']['content']
                
        except Exception as e:
            logger.error(f"Ollama generation failed: {str(e)}")
            raise
    
    def _generate_with_anthropic(self, state: AnalysisState) -> str:
        """Generate report using Anthropic Claude."""
        try:
            from anthropic import Anthropic
            import os
            
            # Prepare context data for the LLM
            context_data = self._prepare_context_data(state)
            
            # Create a comprehensive prompt
            prompt = self._create_llm_prompt(context_data)
            
            # Initialize Anthropic client
            client = Anthropic(api_key=os.getenv('ANTHROPIC_API_KEY'))
            
            # Call Claude
            response = client.messages.create(
                model='claude-3-haiku-20240307',
                max_tokens=4000,
                temperature=0.3,
                system='You are an expert HR analyst and career coach. Generate detailed, personalized CV skill gap analysis reports with actionable insights.',
                messages=[
                    {
                        'role': 'user',
                        'content': prompt
                    }
                ]
            )
            
            return response.content[0].text
            
        except Exception as e:
            logger.error(f"Anthropic generation failed: {str(e)}")
            raise
    
    def _prepare_context_data(self, state: AnalysisState) -> dict:
        """Prepare structured context data for LLM prompt."""
        return {
            'candidate_name': state.cv_structured.personal.name or 'Candidate',
            'target_role': state.target_role,
            'years_of_experience': state.skills_analysis.seniority_indicators.years_exp,
            'leadership_experience': state.skills_analysis.seniority_indicators.leadership,
            'architecture_experience': state.skills_analysis.seniority_indicators.architecture,
            'technical_skills': state.skills_analysis.explicit_skills.get('tech', []),
            'implicit_skills': [skill.skill for skill in state.skills_analysis.implicit_skills],
            'domain_skills': state.skills_analysis.explicit_skills.get('domain', []),
            'soft_skills': state.skills_analysis.explicit_skills.get('soft', []),
            'market_core_requirements': state.market_intelligence.role_requirements.core_skills,
            'market_preferred_requirements': state.market_intelligence.role_requirements.preferred_skills,
            'market_emerging_trends': state.market_intelligence.role_requirements.emerging_trends,
            'market_demand_level': state.market_intelligence.market_insights.demand_level,
            'market_salary_range': state.market_intelligence.market_insights.salary_range,
            'market_growth_areas': state.market_intelligence.market_insights.growth_areas,
            'tech_stack_languages': state.market_intelligence.tech_stack_popularity.language,
            'tech_stack_frameworks': state.market_intelligence.tech_stack_popularity.framework,
            'tech_stack_tools': state.market_intelligence.tech_stack_popularity.tools
        }
    
    def _create_llm_prompt(self, context_data: dict) -> str:
        """Create comprehensive prompt for LLM report generation."""
        prompt = f"""
Generate a comprehensive CV skill gap analysis report for {context_data['candidate_name']} 
who is targeting the role of {context_data['target_role']}.

## Candidate Profile:
- Name: {context_data['candidate_name']}
- Years of Experience: {context_data['years_of_experience']}
- Leadership Experience: {'Yes' if context_data['leadership_experience'] else 'No'}
- Architecture Experience: {'Yes' if context_data['architecture_experience'] else 'No'}

## Candidate's Current Skills:
Technical Skills: {', '.join(context_data['technical_skills'][:10])}
Implicit Skills: {', '.join(context_data['implicit_skills'][:10])}
Domain Skills: {', '.join(context_data['domain_skills'][:10])}
Soft Skills: {', '.join(context_data['soft_skills'][:10])}

## Market Requirements for {context_data['target_role']}:
Core Requirements: {', '.join(context_data['market_core_requirements'][:10])}
Preferred Qualifications: {', '.join(context_data['market_preferred_requirements'][:10])}
Emerging Trends: {', '.join(context_data['market_emerging_trends'][:10])}

## Market Insights:
Demand Level: {context_data['market_demand_level']}
Salary Range: {context_data['market_salary_range']}
Growth Areas: {', '.join(context_data['market_growth_areas'][:10])}

## Technology Stack Popularity:
Languages: {', '.join(context_data['tech_stack_languages'][:10])}
Frameworks: {', '.join(context_data['tech_stack_frameworks'][:10])}
Tools: {', '.join(context_data['tech_stack_tools'][:10])}

## Instructions:
Create a detailed, personalized report that includes:

1. EXECUTIVE SUMMARY:
   - Candidate overview with experience level
   - Key strengths identified
   - Primary recommendations
   - Market outlook

2. CANDIDATE PROFILE:
   - Strengths with evidence
   - Current skill set analysis
   - Experience summary

3. MARKET REQUIREMENTS ANALYSIS:
   - Current market landscape
   - Core requirements
   - Preferred qualifications
   - Emerging trends
   - Technology stack popularity

4. SKILL GAP ASSESSMENT:
   - Gap summary (critical, important, nice-to-have)
   - Detailed gap analysis with evidence
   - Gap analysis insights

5. UPSKILLING ROADMAP:
   - 6-week plan with 3 phases
   - Learning goals for each phase
   - Deliverables for each phase
   - Success metrics

6. RECOMMENDED RESOURCES:
   - Free learning platforms
   - Hands-on practice resources
   - Skill-specific resources
   - Professional development resources
   - Certification paths

Make the report highly personalized, actionable, and specific to this candidate's situation. 
Use a professional, encouraging tone that motivates the candidate while being honest about gaps.
Provide concrete, practical recommendations that the candidate can immediately act upon.
Format the report in clean Markdown with appropriate headers and sections.
"""
        return prompt